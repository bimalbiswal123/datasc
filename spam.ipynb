{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8995049121992729 [0.89605735 0.89605735 0.89605735 0.89928058 0.91007194]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_smscategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predict_smscategory\n",
       "0                 ham\n",
       "1                 ham\n",
       "2                 ham\n",
       "3                 ham\n",
       "4                 ham"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "#Logistic regression for Spam filtering\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('NLP_data/smsspamcollection/SMSSpamCollection',delimiter='\\t',names=['smscategory','sms'])\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "df.smscategory.value_counts()\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df.sms, df.smscategory)\n",
    "\n",
    "\n",
    "# #Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "# #Apply Term Frequency Inverse Document Frequency normalization to a sparse matrix of occurrence counts.\n",
    "# #Transform a count matrix to a normalized tf or tf-idf representation\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "\n",
    "\n",
    "\n",
    "# Term Frequency: is a scoring of the frequency of the word in the current document.\n",
    "# Inverse Document Frequency: is a scoring of how rare the word is across documents.\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "scores = cross_val_score(classifier, X_test, y_test, cv=5)\n",
    "print(np.mean(scores), scores)\n",
    "\n",
    "\n",
    "# In[75]:\n",
    "\n",
    "\n",
    "msg = pd.read_csv('NLP_data/Newdata/smsnew.txt', \n",
    "                 delimiter='\\t',names=['smscategory','sms'])\n",
    "msg.head()\n",
    "\n",
    "\n",
    "# In[77]:\n",
    "\n",
    "\n",
    "smsnew=msg.sms\n",
    "newdata=vectorizer.transform(smsnew)\n",
    "##smsnew.head()\n",
    "type(df)\n",
    "\n",
    "\n",
    "# In[78]:\n",
    "\n",
    "\n",
    "predict_smscategory=classifier.predict(newdata)\n",
    "\n",
    "predict_smscategory=pd.DataFrame(predict_smscategory)\n",
    "predict_smscategory.head()\n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "predict_smscategory.rename(columns={0:'predict_smscategory'}, inplace=True)\n",
    "\n",
    "\n",
    "# In[82]:\n",
    "\n",
    "\n",
    "type(predict_smscategory)\n",
    "\n",
    "\n",
    "# In[83]:\n",
    "\n",
    "\n",
    "predict_smscategory.head()\n",
    "\n",
    "\n",
    "# In[85]:\n",
    "\n",
    "\n",
    "#predict_smscategory.to_csv('NLP_data/Newdata/smscategory.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
