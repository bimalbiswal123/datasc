{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt', 'log2'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-77e05794e428>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Random search of parameters, using 3 fold cross validation,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# search across 100 different combinations, and use all available cores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mrf_random\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;31m# Fit the random search model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Churn\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "#####Random Search \n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(df_train[features], df_train[\"Churn\"])\n",
    "\n",
    "rf_random.best_params_\n",
    "\n",
    "# 9. Evaluate model pipeline on test data\n",
    "predrf = rf_random.predict(df_test[features])\n",
    "print(\"Accuracy: \" ,metrics.accuracy_score(df_test[\"Churn\"], predrf))\n",
    "print(metrics.classification_report(df_test[\"Churn\"], predrf))\n",
    "print(metrics.confusion_matrix(df_test[\"Churn\"], predrf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance\n",
      "[0.62424922 0.29280832 0.05466678 0.02330201 0.00416335]\n",
      "Components\n",
      "[[ 6.53737141e-01  7.20858960e-01  2.36333946e-03 -3.38883346e-03\n",
      "   7.34742049e-03 -4.52378280e-03 -2.59893216e-03  3.59907825e-03\n",
      "   2.46009613e-02 -2.60557259e-04  2.28634224e-01]\n",
      " [-1.25384784e-01 -1.95264459e-01 -4.13315656e-04 -5.48171673e-03\n",
      "  -2.91444145e-02 -7.67014840e-03 -2.61885218e-04 -6.03789168e-03\n",
      "   1.76583559e-01  1.03958241e-02  9.55973665e-01]\n",
      " [ 7.04994558e-01 -6.19856431e-01  2.20394828e-03 -1.19866987e-02\n",
      "  -3.33594803e-02 -1.32007015e-02 -2.48403578e-03  5.82210663e-04\n",
      "   3.28028313e-01  2.16656939e-02 -9.61589310e-02]\n",
      " [-2.42645194e-01  2.36377460e-01 -1.12356454e-03 -1.96945538e-02\n",
      "   6.07941237e-02 -2.72625668e-02 -6.25447800e-03 -1.55448187e-02\n",
      "   9.23524304e-01  6.09832557e-02 -1.53374829e-01]\n",
      " [ 2.99860410e-02 -4.61356135e-02  7.05369054e-04  3.86308424e-02\n",
      "   9.94901129e-01  4.30997208e-02 -3.45596981e-03  2.88259643e-02\n",
      "  -3.62555122e-02 -2.40203465e-02  3.25475246e-02]]\n",
      "For n_clusters = 2 The average silhouette_score is : 0.4454927552928927\n",
      "For n_clusters = 3 The average silhouette_score is : 0.46962763509760197\n",
      "For n_clusters = 4 The average silhouette_score is : 0.374181143849341\n",
      "For n_clusters = 5 The average silhouette_score is : 0.41634313702682096\n",
      "For n_clusters = 6 The average silhouette_score is : 0.4252714985590806\n",
      "For n_clusters = 7 The average silhouette_score is : 0.3819442622670352\n",
      "For n_clusters = 8 The average silhouette_score is : 0.40322630877073457\n",
      "For n_clusters = 9 The average silhouette_score is : 0.4053435811828225\n",
      "For n_clusters = 10 The average silhouette_score is : 0.4158390899680507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0    550\n",
       "0.0    471\n",
       "2.0     15\n",
       "Name: Clust, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Camera.csv', sep=';')\n",
    "\n",
    "columns = ['Model', 'Date', 'MaxRes', 'LowRes', 'EffPix', 'ZoomW', 'ZoomT',\n",
    "         'NormalFR', 'MacroFR', 'Storage', 'Weight', 'Dimensions', 'Price']\n",
    "df.columns = columns\n",
    "df.head()\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df['Model'] = df['Model'].apply(lambda s:s.split()[0])\n",
    "df['Model']=df['Model'].astype('object')\n",
    "df.dtypes\n",
    "\n",
    "df1=df.drop([\"Model\", \"Date\"], axis=1)\n",
    "df2=df1.dropna()\n",
    "df.shape\n",
    "\n",
    "## Dimension Reduction \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(df2)\n",
    "print(\"explained_variance\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"Components\")\n",
    "print(pca.components_)\n",
    "\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6,7,8,9,10]\n",
    "\n",
    "# Compute the silhouette scores for each sample\n",
    "for n_clusters in range_n_clusters:\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(df2)\n",
    "    #sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "    #print(\"%d Cluster size %f \",n_clusters,sample_silhouette_values)\n",
    "    \n",
    "    silhouette_avg = silhouette_score(df2, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "from sklearn import metrics\n",
    "k = range(1,11)\n",
    "\n",
    "clusters = [KMeans(n_clusters = c,init = 'k-means++').fit(df2) \n",
    "            for c in k]\n",
    "centr_lst = [cc.cluster_centers_ for cc in clusters]\n",
    "\n",
    "k_distance = [cdist(df2, cent, 'euclidean') for cent in centr_lst]\n",
    "clust_indx = [np.argmin(kd,axis=1) for kd in k_distance]\n",
    "distances = [np.min(kd,axis=1) for kd in k_distance]\n",
    "avg_within = [np.sum(dist)/df2.shape[0] for dist in distances]\n",
    "\n",
    "kidx = 2\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(k, avg_within, 'g*-')\n",
    "ax.plot(k[kidx], avg_within[kidx], marker='o', markersize=12, \\\n",
    "markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Average within-cluster sum of squares')\n",
    "plt.title('Elbow for KMeans clustering (Camera  Data)')\n",
    "\n",
    "from sklearn import cluster\n",
    "k_means = cluster.KMeans(n_clusters=3)\n",
    "kmf=k_means.fit(df2)\n",
    "\n",
    "P_kmeans = kmf.predict(df2)\n",
    "#P_kmeans=P_kmeans.astype('object')\n",
    "Clust=pd.DataFrame(P_kmeans)\n",
    "\n",
    "dfwithClust=pd.concat([df,Clust], axis=1)\n",
    "dfwithClust.rename(columns={0:'Clust'},inplace=True)\n",
    "dfwithClust.head()\n",
    "\n",
    "dfwithClust.Clust.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
